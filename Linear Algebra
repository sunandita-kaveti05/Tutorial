<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linear Algebra for Machine Learning</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300&display=swap" rel="stylesheet">
    <style>
        body {
background: linear-gradient(to left, #e0f7ff, #8ecae6);

            margin: 0;
            font-family: 'Poppins', sans-serif;
            padding: 20px;
            color: #333;
        }
        header {
            text-align: center;
            margin-bottom: 20px;
        }
        h1 {
            font-size: 3rem;
            font-weight: 300;
        }
        .section {
            margin: 20px 0;
            padding: 20px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
        }
        .section h2 {
            font-size: 2rem;
            margin: 0;
        }
        .section p {
            font-size: 1.2rem;
        }
        .section ul {
            list-style-type: disc;
            margin-left: 20px;
        }
        footer {
            text-align: center;
            margin-top: 40px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Linear Algebra for Machine Learning</h1>
    </header>

    <div class="section">
        <h2>Introduction to Linear Algebra</h2>
        <p>Linear algebra is a branch of mathematics that deals with vectors, matrices, and linear transformations. It forms the foundation for various machine learning algorithms, enabling data representation and manipulation in multidimensional spaces.</p>
    </div>

    <div class="section">
        <h2>Key Concepts</h2>
        <ul>
            <li><strong>Vectors:</strong> A vector is a one-dimensional array of numbers. In machine learning, vectors often represent data points or feature sets.</li>
            <li><strong>Matrices:</strong> A matrix is a two-dimensional array of numbers. Matrices are used to represent datasets, where rows may represent samples and columns represent features.</li>
            <li><strong>Matrix Operations:</strong> Key operations include addition, subtraction, and multiplication. Understanding these operations is crucial for algorithm implementation.</li>
            <li><strong>Determinants and Inverses:</strong> The determinant provides information about the properties of a matrix, while the inverse is useful in solving systems of equations.</li>
            <li><strong>Eigenvalues and Eigenvectors:</strong> These concepts are essential for dimensionality reduction techniques like Principal Component Analysis (PCA).</li>
        </ul>
    </div>

    <div class="section">
        <h2>Vectors</h2>
        <p>A vector is a quantity defined by both a magnitude and a direction. In machine learning, vectors can represent various entities such as:</p>
        <ul>
            <li>Data points in feature space</li>
            <li>Weights in a model</li>
            <li>Gradients in optimization</li>
        </ul>
        <p>Example of a vector:</p>
        <pre><code>[3, 5, 2]</code></pre>
    </div>

    <div class="section">
        <h2>Matrices</h2>
        <p>A matrix is a rectangular array of numbers arranged in rows and columns. For example:</p>
        <pre><code>
        | 1  2  3 |
        | 4  5  6 |
        | 7  8  9 |
        </code></pre>
        <p>In machine learning, matrices are used to represent datasets, where each row corresponds to an instance and each column corresponds to a feature.</p>
    </div>

    <div class="section">
        <h2>Matrix Operations</h2>
        <p>Understanding matrix operations is critical in machine learning:</p>
        <ul>
            <li><strong>Matrix Addition:</strong> Can only be performed on matrices of the same dimension.</li>
            <li><strong>Matrix Multiplication:</strong> The number of columns in the first matrix must equal the number of rows in the second.</li>
            <li><strong>Transposition:</strong> Flipping a matrix over its diagonal, turning rows into columns.</li>
        </ul>
        <p>Example of matrix multiplication:</p>
        <pre><code>
        A = | 1 2 |   B = | 1 0 |
            | 3 4 |       | 0 1 |

        A * B = | 1*1 + 2*0   1*0 + 2*1 |   = | 1  2 |
                 | 3*1 + 4*0   3*0 + 4*1 |     | 3  4 |
        </code></pre>
    </div>

    <div class="section">
        <h2>Eigenvalues and Eigenvectors</h2>
        <p>Eigenvalues and eigenvectors are used in various machine learning applications, particularly in dimensionality reduction techniques like PCA.</p>
        <p>If \( A \) is a square matrix, an eigenvector \( v \) is a non-zero vector such that when \( A \) is multiplied by \( v \), the result is a scalar multiple of \( v \): </p>
        <pre><code>
        A * v = λ * v
        </code></pre>
        <p>Where \( λ \) is the eigenvalue corresponding to eigenvector \( v \).</p>
    </div>

    <div class="section">
        <h2>Applications in Machine Learning</h2>
        <p>Linear algebra is foundational for various machine learning techniques, including:</p>
        <ul>
            <li><strong>Linear Regression:</strong> Uses linear algebra to fit a model to data.</li>
            <li><strong>Support Vector Machines (SVM):</strong> Employs matrices for constructing hyperplanes in high-dimensional space.</li>
            <li><strong>Neural Networks:</strong> Utilize matrix multiplications for forward and backward propagation.</li>
            <li><strong>PCA:</strong> Uses eigenvalues and eigenvectors to reduce the dimensionality of data.</li>
        </ul>
    </div>

    <footer>
        <p>&copy; 2024 Linear Algebra for Machine Learning</p>
    </footer>
</body>
</html>
